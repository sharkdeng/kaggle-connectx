\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
     \usepackage[nonatbib]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{natbib} 
\title{New Reinforcement Learning in ConnectX}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
Limin Deng \\
the College of Computer Science and Engineering\\
 the Australian National University\\
  Canberra, Australia\\
  \texttt{u6849956@anu.edu.au} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a new approach to tackle the ConnectX. Our approach achieved in the Kaggle ConnectX Challenge.
\end{abstract}

\section{Introduction}


\section{Related Work}
\subsection{Q-Learning}
\begin{equation}
Q^{new}(s_t, a_t)  \leftarrow (1-\alpha)Q(s_t, a_t) + \alpha \cdot \left(r_t + \gamma \cdot \mathop{\arg\max}_{a}  Q(s_{t+1}, a) \right)
\end{equation}
Where Q is the function $Q: S \times A \rightarrow R$, $r_t$ is the reward received when moving from the state $s_t$ to the state $s_{t+1}$, $\alpha$ is the learning rate ($ 0 < \alpha < 1$), $\gamma$ is the discount factor ($0 \leq \gamma \leq 1$).
\subsection{Deep Q-Learning (DQN)}

\section{Methods}

\section{Experiments}


\section{Results}

We 
\begin{table}[!htp]
\centering
\begin{tabular}{c|c}
\toprule
Method & Score \\
\toprule
random select & 446.3 \\
\hline
heuristic select & 600.0 \\
\hline
Q-Learning & \\
\hline
Deep Q-Learning & \\
\bottomrule
\end{tabular}
\caption{Methods comparison}
\label{tab:methods}
\end{table}



\bibliographystyle{agsm}
\bibliography{ref}

\end{document}
